---
Fecha de creaci贸n: 2025-09-02 00:23
Fecha de Modificaci贸n: 2025-09-02 00:23
tags: 
Tema:
---


##  Idea/Concepto 
La ventana de contexto de un modelo de lenguaje es el n煤mero m谩ximo de tokens que puede procesar de forma simult谩nea al generar texto. Funciona como una memoria a corto plazo: el modelo solo considera la informaci贸n dentro de esa ventana y descarta lo que queda fuera. Esta restricci贸n surge del costo computacional O(n虏路d) del mecanismo de autoatenci贸n, lo que la convierte en un recurso finito y un cuello de botella. Para preservar el orden de los tokens, se a帽aden codificaciones posicionales a los embeddings, incorporando la informaci贸n de posici贸n directamente en sus vectores. En modelos generativos, se aplica un enmascaramiento causal, que bloquea los tokens futuros antes del softmax para mantener la naturaleza autorregresiva. Adem谩s, la atenci贸n multi-cabeza aprovecha la ventana dividiendo el espacio de representaci贸n en subespacios independientes, lo que permite capturar simult谩neamente relaciones sint谩cticas y sem谩nticas m谩s complejas. En la pr谩ctica, se distingue entre la ventana fija del modelo y las estrategias de gesti贸n de sesi贸n, que permiten aprovechar de manera m谩s eficiente este l铆mite en aplicaciones reales.

##  Puntos Claves (Opcional)
- 

##  Connections
- [[ ]]

##  Personal Insight (Opcional)
- 
## Ь Recursos (Opcional)
- 