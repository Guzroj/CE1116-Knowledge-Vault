---
Fecha de creaci贸n: 2025-09-02 00:22
Fecha de Modificaci贸n: 2025-09-02 00:22
tags: 
Tema:
---


##  Idea/Concepto 

Un Large Language Model (LLM) es un modelo de inteligencia artificial basado en la arquitectura Transformer, t铆picamente usando la pila de decodificadores con autoatenci贸n enmascarada para generar texto. Representa el lenguaje en tokens (palabras, subpalabras o secuencias de caracteres) y emplea autoatenci贸n con codificaciones posicionales para capturar dependencias de corto y largo alcance en paralelo. Cada bloque Transformer incluye redes feed-forward, conexiones residuales y normalizaci贸n de capa, esenciales para la estabilidad y el aprendizaje profundo. El entrenamiento ocurre en dos etapas: un preentrenamiento masivo con grandes vol煤menes de texto y un ajuste fino (fine-tuning) para tareas espec铆ficas. Los LLMs poseen miles de millones de par谩metros y presentan capacidades emergentes, lo que les permite generar texto coherente y resolver tareas complejas. Sin embargo, su rendimiento est谩 limitado por la ventana de contexto, que restringe la cantidad de informaci贸n procesable en cada paso.
##  Puntos Claves (Opcional)
- 

##  Connections
- [[ ]]

##  Personal Insight (Opcional)
- 
## Ь Recursos (Opcional)
- 